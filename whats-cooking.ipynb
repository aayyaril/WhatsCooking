{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "from __future__ import print_function\n",
    "import json\n",
    "from pprint import pprint\n",
    "import simplejson as json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from operator import itemgetter\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('train.json', encoding='utf-8') as data_file:\n",
    "    train = json.loads(data_file.read())\n",
    "    #pprint(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('test.json', encoding='utf-8') as data_file:\n",
    "    test = json.loads(data_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "traindf=pd.DataFrame(train)\n",
    "testdf=pd.DataFrame(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "traindf['ingredients_string']= [' '.join([WordNetLemmatizer().lemmatize(re.sub('[^A-Za-z]', ' ', line)) for line in lists]).strip() for lists in traindf['ingredients']]\n",
    "testdf['ingredients_string']= [' '.join([WordNetLemmatizer().lemmatize(re.sub('[^A-Za-z]', ' ', line)) for line in lists]).strip() for lists in testdf['ingredients']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#traindf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "traindf['cuisine'] = traindf['cuisine'].apply(lambda x: 0 if (x ==\"italian\" or x==\"mexican\") else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stwords=['pepper','salt','oil','garlic','fresh','ground','onion','black','chicken','chopped','tomatoes','red','powder'\n",
    "          ,'tomato','flour','sauce','green','juice','dried','water','white','lime','butter','olive','cloves','white',\n",
    "        'vegetable','chopped','egg','lemon','vinegar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39774, 4)\n"
     ]
    }
   ],
   "source": [
    "ytrain1 = traindf.cuisine\n",
    "xtrain1= traindf.ingredients_string\n",
    "xtest = testdf.ingredients_string\n",
    "print(traindf.shape)\n",
    "#xtrain1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xtrain=xtrain1.tail(15000)\n",
    "ytrain=ytrain1.tail(15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xxtrain=xtrain1.head(4000)\n",
    "yytrain=ytrain1.head(4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xtest=xtest.head(4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tokens(x):\n",
    "    return x.split('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import model_selection\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#vec=TfidfVectorizer(tokenizer=tokens,stop_words=('english'),\n",
    " #                          ngram_range = ( 1 , 1 ),analyzer=\"word\", \n",
    "#                         max_df = .57 , binary=False , token_pattern=r'\\w+' , sublinear_tf=False)\n",
    "vec=CountVectorizer(stop_words=('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Learn vocabulary and idf, return term-document matrix.\n",
    "xtrain=vec.fit_transform(xtrain).todense()\n",
    "#Transform documents to document-term matrix.\n",
    "xxtrain=vec.transform(xxtrain).todense()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtest=vec.transform(xtest).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 2420)\n"
     ]
    }
   ],
   "source": [
    "print(xtrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 2420)\n"
     ]
    }
   ],
   "source": [
    "print(xxtrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 2420)\n"
     ]
    }
   ],
   "source": [
    "print(xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Logistic regression \n",
    "from sklearn import grid_search\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#cv = model_selection.KFold(3)\n",
    "parameters = {'C':[1, 10]}\n",
    "clf = LogisticRegression()\n",
    "classifier_lr = grid_search.GridSearchCV(clf,parameters,cv=3,scoring='roc_auc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1, param_grid={'C': [1, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_lr.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aayya\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:438: ChangedBehaviorWarning: The long-standing behavior to use the estimator's score function in GridSearchCV.score has changed. The scoring parameter is now used.\n",
      "  ChangedBehaviorWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.98260749285834037"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_lr.score(xtrain,ytrain) #AUC: 0.999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "0.965628877313\n"
     ]
    }
   ],
   "source": [
    "print(classifier_lr.best_estimator_)\n",
    "# print(optimized_lr.cv_results_)\n",
    "\n",
    "# evaluate on holdout\n",
    "from sklearn.metrics import roc_auc_score\n",
    "y_pred = classifier_lr.predict_proba(xxtrain)[:, 1]\n",
    "\n",
    "roc_on_test = roc_auc_score(yytrain, y_pred)\n",
    "print(roc_on_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#GBM\n",
    "from sklearn import grid_search\n",
    "parameters = {'n_estimators':[150],'max_features':[120],'learning_rate':[.2],'max_depth':[8]}\n",
    "#learning_rate=[.2,.3,.4,.6,.7]\n",
    "#n_estimators = [10]\n",
    "#max_features = [5, 10]\n",
    "\n",
    "from sklearn import ensemble\n",
    "clf = ensemble.GradientBoostingClassifier()\n",
    "classifier_GBM = grid_search.GridSearchCV(clf,parameters,cv=3,scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=100, presort='auto', random_state=None,\n",
       "              subsample=1.0, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'learning_rate': [0.2], 'max_features': [120], 'n_estimators': [150], 'max_depth': [8]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_GBM.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9647974367055026"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_GBM.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aayya\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:438: ChangedBehaviorWarning: The long-standing behavior to use the estimator's score function in GridSearchCV.score has changed. The scoring parameter is now used.\n",
      "  ChangedBehaviorWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.99343101317825533"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_GBM.score(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.2, loss='deviance', max_depth=8,\n",
      "              max_features=120, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=150, presort='auto', random_state=None,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "0.966297644054\n"
     ]
    }
   ],
   "source": [
    "print(classifier_GBM.best_estimator_)\n",
    "\n",
    "\n",
    "# evaluate on text data(xxtrain and yytrain)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "y_pred = classifier_GBM.predict_proba(xxtrain)[:, 1]\n",
    "\n",
    "roc_on_test = roc_auc_score(yytrain, y_pred)\n",
    "print(roc_on_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#RF\n",
    "from sklearn import grid_search\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#cv = model_selection.KFold()\n",
    "parameters = {'n_estimators':[50],'max_features':[15, 20, 25],'max_depth':[6]}\n",
    "#estimators = [10, 20, 30, 40, 50]\n",
    "#max_features = [5, 10, 15, 20, 25]\n",
    "#max_depth = [3, 4, 5, 6]\n",
    "\n",
    "\n",
    "from sklearn import ensemble\n",
    "clf = ensemble.RandomForestClassifier(criterion='gini')\n",
    "classifier_rf = grid_search.GridSearchCV(clf,parameters,cv=3,scoring='roc_auc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'max_features': [15, 20, 25], 'n_estimators': [50], 'max_depth': [6]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_rf.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.893146702305\n"
     ]
    }
   ],
   "source": [
    "print(classifier_rf.best_estimator_)\n",
    "# print(optimized_lr.cv_results_)\n",
    "\n",
    "# evaluate on holdout\n",
    "from sklearn.metrics import roc_auc_score\n",
    "y_pred = classifier_rf.predict_proba(xxtrain)[:, 1]\n",
    "\n",
    "roc_on_test = roc_auc_score(yytrain, y_pred)\n",
    "print(roc_on_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aayya\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:438: ChangedBehaviorWarning: The long-standing behavior to use the estimator's score function in GridSearchCV.score has changed. The scoring parameter is now used.\n",
      "  ChangedBehaviorWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.91390366685822055"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_rf.score(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.913404071281311"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_rf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testdf=testdf.head(4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions=classifier_GBM.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testdf['cuisine'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#testdf = testdf.sort('id' , ascending=True)\n",
    "testdf[['id' ,'ingredients_string', 'cuisine' ]].to_csv(\"submission1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
